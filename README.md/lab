# ğŸ§  ai-homelab-mistral-

A home lab AI assistant powered by **Mistral** and **Open WebUI**, deployed in a secure local environment using Docker and VirtualBox.

This project documents how to build, deploy, and run a containerized AI chatbot server locally â€” without relying on OpenAI, internet access, or cloud compute. It's designed for:
- ğŸ“¦ Local-first AI experimentation
- ğŸ” Self-hosted privacy
- ğŸ§ª Infrastructure-as-Code learning
- ğŸ› ï¸ Homelab builders & system integrators

---

## ğŸ“ Architecture

![alt text](image.png)

> Mistral + Open WebUI run in a Docker container inside an Ubuntu-based VirtualBox VM. The host provides persistent storage, bridged networking, and CLI/GUI access. Optionally accessible to other local users (LAN).

---

## ğŸš€ Quick Deploy (with Docker)

Clone the repo and run the deploy script:

```bash
git clone https://github.com/JarrandyR/ai-homelab-mistral-.git
cd ai-homelab-mistral-
bash scripts/deploy.sh


Project Structure
ai-homelab-mistral-/
â”œâ”€â”€ README.md                 # Project overview & guide
â”œâ”€â”€ architecture-diagram.png # High-level architecture visual
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ deploy.sh             # Auto-deploy script (Docker-based)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ setup.md              # Step-by-step install + usage
â”‚   â””â”€â”€ faq.md                # Optional: Troubleshooting & tips

ğŸ“‹ Features

âœ… Fully offline capable (no cloud needed)

ğŸ³ Runs inside a secure Docker container

ğŸ” Local network access with no exposed ports

ğŸ§  Mistral model integration (via Ollama backend)

ğŸ§° Web-based GUI with Open WebUI (localhost)

ğŸ“ Easy-to-follow install steps for beginners

âš™ï¸ Auto-deploy script with volume persistence

ğŸ“„ Documentation
File	Purpose
scripts/deploy.sh
	Spins up the Open WebUI container and maps volumes
docs/setup.md
	Step-by-step setup guide
architecture-diagram.png
	Visual system overview
ğŸ›  Requirements

 Git (to clone repo)

 Docker (latest version)

 VirtualBox (if running inside VM)

 Ubuntu 22.04 LTS recommended

ğŸ™‹ Why Use This?

You want a local ChatGPT-like assistant that runs 100% offline.

You're learning DevOps, infrastructure, Docker, or AI system integration.

Youâ€™re building a home server stack with modular services.

Youâ€™re into privacy-first tools with full control of the backend.

ğŸ” Notes on Security

Uses bridge networking by default to stay on local LAN.

No ports exposed to the internet unless changed manually.

You can add authentication via reverse proxy (NGINX, Traefik) â€” not included in this lab.

ğŸ‘¨â€ğŸ’» Author

Jarrandy Richards
ğŸ“ Winter Haven, FL
ğŸ“§ jarrandyr11@gmail.com

âœ… License

MIT â€” Free to use, modify, and contribute.


## ğŸ’¬ Feedback or Questions?

Open an issue or email me directly at `jarrandyr11@gmail.com`.

If you find this useful, consider â­ï¸ starring the repo or sharing it with others building private LLMs.